---
---

@string{aps = {American Physical Society,}}


@article{xie2024openfinllmsopenmultimodallarge,
      bibtex_show={false},
      title={<strong>Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications</strong>},
      journal={arXiv preprint},
      selected={true},
      year={2024},
      pdf={https://arxiv.org/pdf/2408.11878},
      arxiv={2408.11878},
      author={Qianqian Xie and Dong Li and Mengxi Xiao and Zihao Jiang and Ruoyu Xiang and Xiao Zhang and Zhengyu Chen and Yueru He and Weiguang Han and Yuzhe Yang and Shunian Chen and Yifei Zhang and Lihang Shen and Daniel Kim and Zhiwei Liu and Zheheng Luo and Yangyang Yu and Yupeng Cao and Zhiyang Deng and Zhiyuan Yao and Haohang Li and Duanyu Feng and Yongfu Dai and VijayaSai Somasundaram and Peng Lu and Yilun Zhao and Yitao Long and Guojun Xiong and Kaleb Smith and Honghai Yu and Yanzhao Lai and Min Peng and Jianyun Nie and Jordan W. Suchow and Xiao-Yang Liu and Benyou Wang and Alejandro Lopez-Lira and Jimin Huang and Sophia Ananiadou},
      abstract={Large language models (LLMs) have advanced financial applications, yet they often lack sufficient financial knowledge and struggle with tasks involving multi-modal inputs like tables and time series data. To address these limitations, we introduce Open-FinLLMs, a series of Financial LLMs. We begin with FinLLaMA, pre-trained on a 52 billion token financial corpus, incorporating text, tables, and time-series data to embed comprehensive financial knowledge. FinLLaMA is then instruction fine-tuned with 573K financial instructions, resulting in FinLLaMA-instruct, which enhances task performance. Finally, we present FinLLaVA, a multimodal LLM trained with 1.43M image-text instructions to handle complex financial data types. Extensive evaluations demonstrate FinLLaMA's superior performance over LLaMA3-8B, LLaMA3.1-8B, and BloombergGPT in both zero-shot and few-shot settings across 19 and 4 datasets, respectively. FinLLaMA-instruct outperforms GPT-4 and other Financial LLMs on 15 datasets. FinLLaVA excels in understanding tables and charts across 4 multimodal tasks. Additionally, FinLLaMA achieves impressive Sharpe Ratios in trading simulations, highlighting its robust financial application capabilities. We will continually maintain and improve our models and benchmarks to support ongoing innovation in academia and industry.},
      note={First open-source financial multimodal LLM: FinLLaVA-8B},
      preview={finllava.png},
}


@article{yu2024doinvestorsspeaklouder,
  title={<strong>Do investorsâ€™ actions speak louder than words?</strong>},
  author={Honghai Yu and Zhuo Chen and Yunmiao Zhang and Haining Wang and Yifei Zhang},
  year={2024},
  preview={investors.png},
  abstract={A large body of literature has examined whether posts on social media propagate noise or information. In this paper, we propose that both coexist on Chinese social media platforms but can be distinguished by posters' trading behavior. Individuals may post articles on social media that do not reflect their true opinions, often for impression management purposes, resulting in inconsistency between their words and subsequent actions. Additionally, observing a poster's trading behavior prior to posting can help assess the reliability of their expressed views.},
  note={An extended version of undergraduate thesis, accepted by the 21st Annual Conference on Financial Engineering and Risk Management},
  selected={true},
}


@article{yang2024ucfeusercentricfinancialexpertise,
  title={<strong>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</strong>},
  author={Yuzhe Yang* and Yifei Zhang* and Yan Hu* and Yilin Guo and Ruoli Gan and Yueru He and Mingcong Lei and Xiao Zhang and Haining Wang and Qianqian Xie and Jimin Huang and Honghai Yu and Benyou Wang},
  journal={<strong>NAACL Findings 2025</strong>},
  arxiv={2410.14059},
  primaryClass={q-fin.CP},
  preview={UCFE.png},
  code={https://github.com/TobyYang7/UCFE-Benchmark},
  abstract={This paper introduces the UCFE: User-Centric Financial Expertise benchmark, an innovative framework designed to evaluate the ability of large language models (LLMs) to handle complex real-world financial tasks. UCFE benchmark adopts a hybrid approach that combines human expert evaluations with dynamic, taskspecific interactions to simulate the complexities of evolving financial scenarios. Firstly, we conducted a user study involving 804 participants, collecting their feedback on financial tasks. Secondly, based on this feedback, we created our dataset that encompasses a wide range of user intents and interactions. This dataset serves as the foundation for benchmarking 12 LLM services using the LLM-as-Judge methodology. Our results show a significant alignment between benchmark scores and human preferences, with a Pearson correlation coefficient of 0.78, confirming the effectiveness of the UCFE dataset and our evaluation approach. UCFE benchmark not only reveals the potential of LLMs in the financial sector but also provides a robust framework for assessing their performance and user satisfaction.The benchmark dataset and evaluation code are available.},
  note={A User-Centric framework designed to evaluate LLMs' ability to handle complex financial tasks},
  selected={true},
  bibtex_show={false},
}



@article{yang2025twinmarketscalablebehavioralsocialsimulation,
  title={<strong>TwinMarket: A Scalable Behavioral and SocialSimulation for Financial Markets</strong>},
  author={Yuzhe Yang* and Yifei Zhang* and Minghao Wu* and Kaidi Zhang and Yunmiao Zhang and Honghai Yu and Yan Hu and Benyou Wang},
  arxiv={2502.01506},
  selected={true},
  code={https://github.com/TobyYang7/TwinMarket},
  preview={TwinMarket.jpg},
  abstract={The study of social emergence has long been a central focus in social science.
 Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics.
 Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications.
 Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics.
 In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena.
 Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions.
 Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.},
  note={A multi-agent framework that leverages LLMs to simulate socio-economic systems},
  journal={{<span style="color: red;"><strong>Best Paper Award in Financial AI @ ICLR 2025</strong></span> & selected for <strong>oral</strong> presentation at <strong>ICLR 2025</strong>}},
  selected={true},
  bibtex_show={false},
}