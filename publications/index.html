<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Yifei Zhang </title> <meta name="author" content="Yifei Zhang"> <meta name="description" content="* means Equal Contribution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/nju.png?c1147be53d7aeb502ccd308ef2064fe0"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hoder-zyf.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yifei</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">* means Equal Contribution</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="keyword-filter-buttons mb-4"> <button class="filter-btn active" data-filter="all"> <i class="fas fa-list"></i> All Publications </button> <button class="filter-btn" data-filter="computer science"> <i class="fas fa-laptop-code"></i> CS &amp; Finance </button> <button class="filter-btn" data-filter="finance-only"> <i class="fas fa-chart-line"></i> Finance Only </button> </div> <div class="publications" id="all-publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/finllava-480.webp 480w,/assets/img/publication_preview/finllava-800.webp 800w,/assets/img/publication_preview/finllava-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/finllava.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="finllava.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xie2024openfinllmsopenmultimodallarge" class="col-sm-8"> <div class="title"><strong>Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications 2024</strong></div> <div class="author"> Jimin Huang, Mengxi Xiao, Dong Li, Zihao Jiang, Yuzhe Yang, <em>Yifei Zhang</em>, and <span class="more-authors" title="click to view 38 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '38 more authors' ? 'Lingfei Qian, Yan Wang, Xueqing Peng, Yang Ren, Ruoyu Xiang, Zhengyu Chen, Xiao Zhang, Yueru He, Weiguang Han, Shunian Chen, Lihang Shen, Daniel Kim, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Guojun Xiong, Zhiwei Liu, Zheheng Luo, Zhiyuan Yao, Ruey-Ling Weng, Meikang Qiu, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-Yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Qianqian Xie, Sophia Ananiadou, Junichi Tsujii' : '38 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '20'); ">38 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, </div> <div class="periodical"> First open-source financial multimodal LLM: FinLLaVA-8B </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2408.11878" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2408.11878" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) have advanced financial applications, yet they often lack sufficient financial knowledge and struggle with tasks involving multi-modal inputs like tables and time series data. To address these limitations, we introduce Open-FinLLMs, a series of Financial LLMs. We begin with FinLLaMA, pre-trained on a 52 billion token financial corpus, incorporating text, tables, and time-series data to embed comprehensive financial knowledge. FinLLaMA is then instruction fine-tuned with 573K financial instructions, resulting in FinLLaMA-instruct, which enhances task performance. Finally, we present FinLLaVA, a multimodal LLM trained with 1.43M image-text instructions to handle complex financial data types. Extensive evaluations demonstrate FinLLaMA’s superior performance over LLaMA3-8B, LLaMA3.1-8B, and BloombergGPT in both zero-shot and few-shot settings across 19 and 4 datasets, respectively. FinLLaMA-instruct outperforms GPT-4 and other Financial LLMs on 15 datasets. FinLLaVA excels in understanding tables and charts across 4 multimodal tasks. Additionally, FinLLaMA achieves impressive Sharpe Ratios in trading simulations, highlighting its robust financial application capabilities. We will continually maintain and improve our models and benchmarks to support ongoing innovation in academia and industry.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/investors-480.webp 480w,/assets/img/publication_preview/investors-800.webp 800w,/assets/img/publication_preview/investors-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/investors.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="investors.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yu2024doinvestorsspeaklouder" class="col-sm-8"> <div class="title"><strong>Do investors’ actions speak louder than words? 2024</strong></div> <div class="author"> Honghai Yu, Zhuo Chen, Yunmiao Zhang, Haining Wang, and <em>Yifei Zhang</em> </div> <div class="periodical"> <em></em> </div> <div class="periodical"> An extended version of undergraduate thesis, accepted by the 21st Annual Conference on Financial Engineering and Risk Management </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>A large body of literature has examined whether posts on social media propagate noise or information. In this paper, we propose that both coexist on Chinese social media platforms but can be distinguished by posters’ trading behavior. Individuals may post articles on social media that do not reflect their true opinions, often for impression management purposes, resulting in inconsistency between their words and subsequent actions. Additionally, observing a poster’s trading behavior prior to posting can help assess the reliability of their expressed views.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/UCFE-480.webp 480w,/assets/img/publication_preview/UCFE-800.webp 800w,/assets/img/publication_preview/UCFE-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/UCFE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="UCFE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yang2024ucfeusercentricfinancialexpertise" class="col-sm-8"> <div class="title"><strong>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</strong></div> <div class="author"> Yuzhe Yang<sup>*</sup>, <em>Yifei Zhang<sup>*</sup></em>, Yan Hu<sup>*</sup>, Yilin Guo, Ruoli Gan, Yueru He, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Mingcong Lei, Xiao Zhang, Haining Wang, Qianqian Xie, Jimin Huang, Honghai Yu, Benyou Wang' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '20'); ">7 more authors</span> </div> <div class="periodical"> <em><strong>NAACL Findings 2025</strong></em>, </div> <div class="periodical"> A User-Centric framework designed to evaluate LLMs’ ability to handle complex financial tasks </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2410.14059" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/TobyYang7/UCFE-Benchmark" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This paper introduces the UCFE: User-Centric Financial Expertise benchmark, an innovative framework designed to evaluate the ability of large language models (LLMs) to handle complex real-world financial tasks. UCFE benchmark adopts a hybrid approach that combines human expert evaluations with dynamic, taskspecific interactions to simulate the complexities of evolving financial scenarios. Firstly, we conducted a user study involving 804 participants, collecting their feedback on financial tasks. Secondly, based on this feedback, we created our dataset that encompasses a wide range of user intents and interactions. This dataset serves as the foundation for benchmarking 12 LLM services using the LLM-as-Judge methodology. Our results show a significant alignment between benchmark scores and human preferences, with a Pearson correlation coefficient of 0.78, confirming the effectiveness of the UCFE dataset and our evaluation approach. UCFE benchmark not only reveals the potential of LLMs in the financial sector but also provides a robust framework for assessing their performance and user satisfaction.The benchmark dataset and evaluation code are available.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/TwinMarket-480.webp 480w,/assets/img/publication_preview/TwinMarket-800.webp 800w,/assets/img/publication_preview/TwinMarket-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/TwinMarket.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TwinMarket.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yang2025twinmarketscalablebehavioralsocialsimulation" class="col-sm-8"> <div class="title"><strong>TwinMarket: A Scalable Behavioral and SocialSimulation for Financial Markets</strong></div> <div class="author"> Yuzhe Yang<sup>*</sup>, <em>Yifei Zhang<sup>*</sup></em>, Minghao Wu<sup>*</sup>, Kaidi Zhang, Yunmiao Zhang, Honghai Yu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yan Hu, Benyou Wang' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '20'); ">2 more authors</span> </div> <div class="periodical"> <em><strong>NeurIPS 2025</strong> &amp; <span style="color: red;"><strong>Best Paper Award</strong></span> in Financial AI @ ICLR 2025</em>, </div> <div class="periodical"> A multi-agent framework that leverages LLMs to simulate socio-economic systems </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.01506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/TobyYang7/TwinMarket" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/xiuqi-480.webp 480w,/assets/img/publication_preview/xiuqi-800.webp 800w,/assets/img/publication_preview/xiuqi-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/xiuqi.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xiuqi.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yu2025sharedfortunesandrisks" class="col-sm-8"> <div class="title"><strong>Shared Fortunes and Risks: Stock Price Spillover Effects of Corporate Ties — Evidence from the Chinese Social Media Platform "Xueqiu" 2025</strong></div> <div class="author"> Honghai Yu, Yunmiao Zhang, Zhuo Chen, Chang Zeng, and <em>Yifei Zhang</em> </div> <div class="periodical"> <em></em> </div> <div class="periodical"> <span style="color: red;"><strong>Outstanding Paper, The 7th Conference of the Chinese Society of Optimization, Overall Planning, and Economic Mathematics</strong></span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Based on data from Xueqiu platform spanning 2011-2025, this study constructs social media networks among listed companies and calculates co-mention momentum indicators (CR) to examine momentum spillover effects embedded in social media associations. We find that social media co-mention return indicators have significant cross-sectional explanatory power for future stock returns, remaining robust after controlling for multiple factors. Mechanism analysis based on limited attention theory reveals that this effect is more pronounced among stocks with lower investor attention, and shows stronger predictive performance for non-state-owned enterprises and during periods of high investor sentiment. This paper reveals the unique value of social media co-coverage and provides insights into the role of alternative data in asset pricing mechanisms.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/RD_Agent-480.webp 480w,/assets/img/publication_preview/RD_Agent-800.webp 800w,/assets/img/publication_preview/RD_Agent-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/RD_Agent.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="RD_Agent.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="yang2025r" class="col-sm-8"> <div class="title"><strong>R&amp;D-Agent: An LLM-Agent Framework Towards Autonomous Data Science 2025</strong></div> <div class="author"> Xu Yang, Xiao Yang, Shikai Fang, <em>Yifei Zhang</em>, Jian Wang, Bowen Xian, and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Qizheng Li, Jingyuan Li, Minrui Xu, Yuante Li, Haoran Pan, Yuge Zhang, Weiqing Liu, Yelong Shen, Weizhu Chen, Jiang Bian' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '20'); ">10 more authors</span> </div> <div class="periodical"> <em>arXiv preprint</em>, </div> <div class="periodical"> An LLM-Agent framework towards autonomous data science </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2505.14738" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://arxiv.org/pdf/2505.14738" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Recent advances in AI and ML have transformed data science, yet increasing complexity and expertise requirements continue to hinder progress. Although crowd-sourcing platforms alleviate some challenges, high-level machine learning engineering (MLE) tasks remain labor-intensive and iterative. We introduce R&amp;D Agent, a comprehensive, decoupled, and extensible framework that formalizes the MLE process. R&amp;D-Agent defines the MLE workflow into two phases and six components, turning agent design for MLE from ad-hoc craftsmanship into a principled, testable process. Although several existing agents report promising gains on their chosen components, they can mostly be summarized as a partial optimization from our framework’s simple baseline. Inspired by human experts, we designed efficient and effective agents within this framework that achieve state of-the-art performance. Evaluated on MLE-Bench, the agent built on R&amp;D-Agent ranks as the top-performing machine learning engineering agent, achieving 35.1% any medal rate, demonstrating the ability of the framework to speed up innovation and improve accuracy across a wide range of data science applications.</p> </div> </div> </div> </li> </ol> </div> <script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll(".keyword-filter-buttons .filter-btn"),l=document.querySelectorAll("#all-publications .bibliography li");e.forEach(n=>{n.addEventListener("click",function(){e.forEach(e=>e.classList.remove("active")),this.classList.add("active");const n=this.getAttribute("data-filter");l.forEach(e=>{if("all"===n)e.style.display="block";else{const l=e.textContent.toLowerCase();let c=!1;if("computer science"===n){c=l.includes("computer science")||l.includes("naacl")||l.includes("iclr")||l.includes("llm")||l.includes("language model")||l.includes("benchmark")||l.includes("multimodal")||l.includes("finllm")||l.includes("ucfe")||l.includes("twinmarket")}else if("finance-only"===n){const e=l.includes("computer science")||l.includes("naacl")||l.includes("iclr")||l.includes("llm")||l.includes("language model")||l.includes("benchmark")||l.includes("multimodal")||l.includes("finllm")||l.includes("ucfe")||l.includes("twinmarket");c=(l.includes("finance")||l.includes("financial")||l.includes("stock")||l.includes("market")||l.includes("investment")||l.includes("trading")||l.includes("economic"))&&!e}e.style.display=c?"block":"none"}})})})});</script> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yifei Zhang. Last updated: October 11, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.getElementById("WeChatBtn");wechatBtn.onclick=function(){wechatModal.style.display="block"},window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"* means Equal Contribution",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-the-power-of-saying-no",title:"The Power of Saying No",description:"Exploring the importance of declining unsuitable opportunities in career development",section:"Posts",handler:()=>{window.location.href="/blog/2024/the-ability-to-say-no/"}},{id:"post-the-blue-grass-story",title:"The Blue Grass Story",description:"An interesting story about perception and wisdom",section:"Posts",handler:()=>{window.location.href="/blog/2024/a-story/"}},{id:"post-thoughts-about-the-next-stage-research",title:"Thoughts about the next stage research",description:"Some ideas about the next stage research",section:"Posts",handler:()=>{window.location.href="/blog/2024/next-stage-thoughts/"}},{id:"post-an-unforgettable-night-at-jacky-cheung-39-s-concert",title:"An Unforgettable Night at Jacky Cheung's Concert",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/zhangxueyou-concerts/"}},{id:"post-undergraduate-thesis-completed",title:"Undergraduate Thesis Completed",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/undergraduate-thesis/"}},{id:"news-blush-graduate-from-nanjing-university",title:'<img class="emoji" title=":blush:" alt=":blush:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png" height="20" width="20"> Graduate from Nanjing University!',description:"",section:"News"},{id:"news-excited-to-start-a-ra-position-at-cuhk-sz-with-prof-benyou-wang",title:"\ud83d\udd2c Excited to start a RA position at CUHK(SZ) with Prof. Benyou Wang....",description:"",section:"News"},{id:"news-blush-begin-new-journey-as-a-master-student-at-nanjing-university",title:'<img class="emoji" title=":blush:" alt=":blush:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png" height="20" width="20"> Begin new journey as a master student at Nanjing University',description:"",section:"News"},{id:"news-star2-one-paper-accepted-by-the-21st-annual-conference-on-financial-engineering-and-risk-management",title:'<img class="emoji" title=":star2:" alt=":star2:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png" height="20" width="20"> One paper accepted by The 21st Annual Conference on Financial Engineering and...',description:"",section:"News"},{id:"news-star2-one-paper-accepted-by-naacl-findings-2025-you-can-find-the-paper-here",title:'<img class="emoji" title=":star2:" alt=":star2:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png" height="20" width="20"> One paper accepted by NAACL Findings 2025. You can find the paper...',description:"",section:"News"},{id:"news-innocent-great-honor-to-give-a-talk-at-financial-ai-iclr-2025-and-won-the-best-paper-award-1-out-of-53-you-can-find-the-paper-here",title:'<img class="emoji" title=":innocent:" alt=":innocent:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f607.png" height="20" width="20"> Great Honor to give a talk at Financial AI @ ICLR 2025...',description:"",section:"News"},{id:"news-tada-happy-to-start-my-intern-at-msra-beijing",title:'<img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Happy to start my intern at MSRA-Beijing!',description:"",section:"News"},{id:"news-honored-to-have-one-paper-selected-as-the-outstanding-paper-award-for-the-7th-conference-of-the-chinese-society-of-optimization-overall-planning-and-economic-mathematics",title:"\ud83c\udf93 Honored to have one paper selected as the Outstanding Paper Award for...",description:"",section:"News"},{id:"news-star2-one-paper-accepted-by-neurips-2025-you-can-find-the-paper-here",title:'<img class="emoji" title=":star2:" alt=":star2:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png" height="20" width="20"> One paper accepted by NeurIPS 2025. You can find the paper here....',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%66_%7A%68%61%6E%67@%73%6D%61%69%6C.%6E%6A%75.%65%64%75.%63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=b4rGdr4AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Hoder-zyf","_blank")}},{id:"socials-zotero",title:"Zotero",section:"Socials",handler:()=>{window.open("https://www.zotero.org/hoderzyf","_blank")}},{id:"socials-qq",title:"QQ",section:"Socials",handler:()=>{window.open("tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=1076289577&website=www.oicqzone.com/","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>